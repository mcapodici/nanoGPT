{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is a comparison of NanoGPT (https://github.com/karpathy/nanoGPT) trained using it's original softmax you know and love, and the modified softmax1 (see Evan Miller's https://www.evanmiller.org/attention-is-off-by-one.html).\n",
        "\n",
        "The source code, with all the parameters used and modified code can be found here https://github.com/softmax1/nanoGPT_softmax1_reddit\n",
        "\n",
        "WandB logs:\n",
        "https://wandb.ai/martin-capodici/nanoGPT_softmax1?workspace=user-martin-capodici\n",
        "\n",
        "Weight Kurtosis and Sample outputs can be found in the outputs in this Colab."
      ],
      "metadata": {
        "id": "xk6FIVlPNCMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch numpy transformers datasets tiktoken wandb tqdm"
      ],
      "metadata": {
        "id": "thJ0IgYEC9PY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjjA_i3AXhGt"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/softmax1/nanoGPT_softmax1_reddit\n",
        "%cd nanoGPT_softmax1_reddit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout softmax1-final"
      ],
      "metadata": {
        "id": "fCror07jElqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir out-reddit-softmax-zero\n",
        "!wget -O './out-reddit-softmax-zero/ckpt.pt' https://huggingface.co/mcapodici/nanoGPTSoftmax1RedditSydney/resolve/main/softmax0/ckpt.pt"
      ],
      "metadata": {
        "id": "0d49xXgDA9RK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir out-reddit-softmax-one\n",
        "!wget -O './out-reddit-softmax-one/ckpt.pt' https://huggingface.co/mcapodici/nanoGPTSoftmax1RedditSydney/resolve/main/softmax1/ckpt.pt"
      ],
      "metadata": {
        "id": "oO8sOBdhF0rW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python kurtosis.py config/train_reddit_softmax0.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-squFXujEhcb",
        "outputId": "749750d0-e8bf-4e63-f3b0-982693269006"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding config with config/train_reddit_softmax0.py:\n",
            "gradient_accumulation_steps = 1\n",
            "batch_size = 64\n",
            "block_size = 256 # context of up to 256 previous characters\n",
            "n_layer = 6\n",
            "n_head = 6\n",
            "n_embd = 768\n",
            "dropout = 0.2\n",
            "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\n",
            "max_iters = 100000\n",
            "lr_decay_iters = 100000\n",
            "min_lr = 1e-4 # learning_rate / 10 usually\n",
            "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\n",
            "warmup_iters = 100 # not super necessary potentially\n",
            "eval_interval = 1000\n",
            "eval_iters = 20\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "dataset = 'reddit'\n",
            "\n",
            "out_dir = 'out-reddit-softmax-zero'\n",
            "wandb_log = True\n",
            "wandb_project = 'nanoGPT_softmax1'\n",
            "wandb_run_name = 'reddit-mini-gpt-softmax-zero'\n",
            "use_softmax1 = False\n",
            "detect_from_iter_num = -1\n",
            "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
            "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
            "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
            "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
            "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
            "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
            "number of parameters: 81.11M\n",
            "transformer.wte.weight             :    42.16788\n",
            "transformer.wpe.weight             :    23.75124\n",
            "transformer.h.0.ln_1.weight        :     0.72363\n",
            "transformer.h.0.attn.c_attn.weight :     7.25830\n",
            "transformer.h.0.attn.c_proj.weight :    18.83367\n",
            "transformer.h.0.ln_2.weight        :    -1.17625\n",
            "transformer.h.0.mlp.c_fc.weight    :     1.18973\n",
            "transformer.h.0.mlp.c_proj.weight  :    27.62165\n",
            "transformer.h.1.ln_1.weight        :     5.95062\n",
            "transformer.h.1.attn.c_attn.weight :     3.57675\n",
            "transformer.h.1.attn.c_proj.weight :    10.24569\n",
            "transformer.h.1.ln_2.weight        :    16.43078\n",
            "transformer.h.1.mlp.c_fc.weight    :     0.85820\n",
            "transformer.h.1.mlp.c_proj.weight  :    49.08110\n",
            "transformer.h.2.ln_1.weight        :     6.58376\n",
            "transformer.h.2.attn.c_attn.weight :     1.69715\n",
            "transformer.h.2.attn.c_proj.weight :     2.34975\n",
            "transformer.h.2.ln_2.weight        :    14.30544\n",
            "transformer.h.2.mlp.c_fc.weight    :     0.95321\n",
            "transformer.h.2.mlp.c_proj.weight  :    25.41860\n",
            "transformer.h.3.ln_1.weight        :     6.55532\n",
            "transformer.h.3.attn.c_attn.weight :     2.48616\n",
            "transformer.h.3.attn.c_proj.weight :     0.43861\n",
            "transformer.h.3.ln_2.weight        :    18.27010\n",
            "transformer.h.3.mlp.c_fc.weight    :     0.88617\n",
            "transformer.h.3.mlp.c_proj.weight  :    19.23478\n",
            "transformer.h.4.ln_1.weight        :    11.34787\n",
            "transformer.h.4.attn.c_attn.weight :     1.70275\n",
            "transformer.h.4.attn.c_proj.weight :     1.60929\n",
            "transformer.h.4.ln_2.weight        :    25.65867\n",
            "transformer.h.4.mlp.c_fc.weight    :     1.02283\n",
            "transformer.h.4.mlp.c_proj.weight  :     7.47641\n",
            "transformer.h.5.ln_1.weight        :    20.51977\n",
            "transformer.h.5.attn.c_attn.weight :     0.71629\n",
            "transformer.h.5.attn.c_proj.weight :     8.41872\n",
            "transformer.h.5.ln_2.weight        :    86.08651\n",
            "transformer.h.5.mlp.c_fc.weight    :     0.10606\n",
            "transformer.h.5.mlp.c_proj.weight  :     6.78494\n",
            "transformer.ln_f.weight            :     8.79526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python kurtosis.py config/train_reddit_softmax1.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7E7phoabHMuM",
        "outputId": "7842ec8f-877d-416e-bf89-3cc8f15fdca9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding config with config/train_reddit_softmax1.py:\n",
            "gradient_accumulation_steps = 1\n",
            "batch_size = 64\n",
            "block_size = 256 # context of up to 256 previous characters\n",
            "n_layer = 6\n",
            "n_head = 6\n",
            "n_embd = 768\n",
            "dropout = 0.2\n",
            "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\n",
            "max_iters = 100000\n",
            "lr_decay_iters = 100000\n",
            "min_lr = 1e-4 # learning_rate / 10 usually\n",
            "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\n",
            "warmup_iters = 100 # not super necessary potentially\n",
            "eval_interval = 1000\n",
            "eval_iters = 20\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "dataset = 'reddit'\n",
            "\n",
            "out_dir = 'out-reddit-softmax-one'\n",
            "wandb_log = True\n",
            "wandb_project = 'nanoGPT_softmax1'\n",
            "wandb_run_name = 'reddit-mini-gpt-softmax-one'\n",
            "use_softmax1 = True\n",
            "softmax1_c = 1e-3\n",
            "detect_from_iter_num = -1\n",
            "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
            "Used softmax1, c = 0.001\n",
            "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
            "Used softmax1, c = 0.001\n",
            "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
            "Used softmax1, c = 0.001\n",
            "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
            "Used softmax1, c = 0.001\n",
            "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
            "Used softmax1, c = 0.001\n",
            "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
            "Used softmax1, c = 0.001\n",
            "number of parameters: 81.11M\n",
            "transformer.wte.weight             :    44.19418\n",
            "transformer.wpe.weight             :    46.61060\n",
            "transformer.h.0.ln_1.weight        :     0.39913\n",
            "transformer.h.0.attn.c_attn.weight :     6.20421\n",
            "transformer.h.0.attn.c_proj.weight :    23.98224\n",
            "transformer.h.0.ln_2.weight        :    -1.30030\n",
            "transformer.h.0.mlp.c_fc.weight    :     0.93020\n",
            "transformer.h.0.mlp.c_proj.weight  :     4.47082\n",
            "transformer.h.1.ln_1.weight        :     8.11839\n",
            "transformer.h.1.attn.c_attn.weight :     3.52192\n",
            "transformer.h.1.attn.c_proj.weight :    22.55689\n",
            "transformer.h.1.ln_2.weight        :    13.32005\n",
            "transformer.h.1.mlp.c_fc.weight    :     0.51985\n",
            "transformer.h.1.mlp.c_proj.weight  :     8.10128\n",
            "transformer.h.2.ln_1.weight        :     4.77572\n",
            "transformer.h.2.attn.c_attn.weight :     1.43841\n",
            "transformer.h.2.attn.c_proj.weight :     1.23384\n",
            "transformer.h.2.ln_2.weight        :    12.91027\n",
            "transformer.h.2.mlp.c_fc.weight    :     0.61436\n",
            "transformer.h.2.mlp.c_proj.weight  :     5.61041\n",
            "transformer.h.3.ln_1.weight        :     6.94772\n",
            "transformer.h.3.attn.c_attn.weight :     2.35409\n",
            "transformer.h.3.attn.c_proj.weight :     0.56070\n",
            "transformer.h.3.ln_2.weight        :    16.46345\n",
            "transformer.h.3.mlp.c_fc.weight    :     0.63739\n",
            "transformer.h.3.mlp.c_proj.weight  :     5.44106\n",
            "transformer.h.4.ln_1.weight        :     9.78187\n",
            "transformer.h.4.attn.c_attn.weight :     1.65553\n",
            "transformer.h.4.attn.c_proj.weight :     0.89932\n",
            "transformer.h.4.ln_2.weight        :    31.47727\n",
            "transformer.h.4.mlp.c_fc.weight    :     0.90368\n",
            "transformer.h.4.mlp.c_proj.weight  :     8.78070\n",
            "transformer.h.5.ln_1.weight        :    22.09485\n",
            "transformer.h.5.attn.c_attn.weight :     0.78189\n",
            "transformer.h.5.attn.c_proj.weight :     4.69297\n",
            "transformer.h.5.ln_2.weight        :   107.59106\n",
            "transformer.h.5.mlp.c_fc.weight    :     0.50903\n",
            "transformer.h.5.mlp.c_proj.weight  :     5.21961\n",
            "transformer.ln_f.weight            :     7.46873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python sample.py config/train_reddit_softmax0.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSri79RkHZax",
        "outputId": "8e350a30-2f47-4d5d-c042-5fc8adc49044"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding config with config/train_reddit_softmax0.py:\n",
            "gradient_accumulation_steps = 1\n",
            "batch_size = 64\n",
            "block_size = 256 # context of up to 256 previous characters\n",
            "n_layer = 6\n",
            "n_head = 6\n",
            "n_embd = 768\n",
            "dropout = 0.2\n",
            "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\n",
            "max_iters = 100000\n",
            "lr_decay_iters = 100000\n",
            "min_lr = 1e-4 # learning_rate / 10 usually\n",
            "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\n",
            "warmup_iters = 100 # not super necessary potentially\n",
            "eval_interval = 1000\n",
            "eval_iters = 20\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "dataset = 'reddit'\n",
            "\n",
            "out_dir = 'out-reddit-softmax-zero'\n",
            "wandb_log = True\n",
            "wandb_project = 'nanoGPT_softmax1'\n",
            "wandb_run_name = 'reddit-mini-gpt-softmax-zero'\n",
            "use_softmax1 = False\n",
            "detect_from_iter_num = -1\n",
            "\n",
            "start = \"The best fried chicken restaurant I would recommend is\"\n",
            "max_new_tokens = 100\n",
            "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
            "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
            "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
            "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
            "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
            "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
            "number of parameters: 81.11M\n",
            "No meta.pkl found, assuming GPT-2 encodings...\n",
            "The best fried chicken restaurant I would recommend is the Crystal Palace, but that's a bit far for you. \n",
            "Yeah, if you take it to a charity, they can cut your losses by adding cash. I had an appointment last week for a private clinic. \n",
            "\n",
            "Not sure about the local one, but there are plenty of good and cheap restaurants there. \n",
            "Yep, got it. I'd recommend the Korean place on Pitt Street. \n",
            "I'm with you here. It's just a joke on /r/\n",
            "---------------\n",
            "The best fried chicken restaurant I would recommend is in the Inner West. \n",
            "\n",
            "The [Riverside Hotel](http://www.urbanspoon.com/r/70/170314/restaurant/CBD/Riverside-Hotel-Sydney) is very good for all budgets based on reviews. \n",
            "\n",
            "If you are also in the city, The [Pizza Box](http://www.pizza Mario.com.au/) is also very good, but also very pricey.\n",
            "---------------\n",
            "The best fried chicken restaurant I would recommend is La Mesa in Haymarket, I personally just go to Obiamo (Sydney Town Centre).\n",
            "\n",
            "Also, the best dumpling place is the one next to the Capitol Theatre (the one near Central) in Haymarket. The food is great and the service is so much better.\n",
            "\n",
            "Also very nearly as good as the gelato at Messina or Messina. And the gelato Messina Gelato Messina is also worth checking out. Only problem is that the\n",
            "---------------\n",
            "The best fried chicken restaurant I would recommend is the one on George St near Central station.\n",
            "\n",
            "Also the little Viet place on Sussex st is open till late, and the big one on the inside of the Town Hall train station.\n",
            "\n",
            "Also I'm not sure that's open until like 9pm.\n",
            "If you have a spare ticket to the concert, pm me. I'm on my phone so can't take it off your hands, but I'm on my phone so I can't link enough people to this thread.\n",
            "H\n",
            "---------------\n",
            "The best fried chicken restaurant I would recommend is **Lane Cove** in Cronulla, they have two shops and two-up shop, and one in an alleyway.\n",
            "\n",
            "http://www.lane Cove.com.au/\n",
            "\n",
            "The organic place opposite the Royal Victoria Golf Club does a pretty good one, but it seems pretty expensive.\n",
            "\n",
            "Petersham is also good.\n",
            "\n",
            "Beware of the el nino and the rest of the guys who grope around them, and (more specifically) I really\n",
            "---------------\n",
            "The best fried chicken restaurant I would recommend is in the rocks and you can get it with a salad. \n",
            "Here's a sneak peek of /r/Drama using the [top posts](https://np.reddit.com/r/Drama/top/?sort=top&amp;t=year) of the year!\n",
            "\n",
            "\\#1: [Fantastic Race Sydney - **$80 (includes food, snacks, beverages)** - **Book** - Central Station](https://fantasticrace.\n",
            "---------------\n",
            "The best fried chicken restaurant I would recommend is The Counter Burger (also in North Sydney), which is a pretty classic, but more relaxed atmosphere and the fact that they are next to the usual pub puts two of the best burgers in town.\n",
            "\n",
            "The best bar though is the one on the corner of Pitt and George, which is on the corner of Pitt and Goulburn. It's very close to the station and has a great vibe.\n",
            "\n",
            "I'd recommend the Crows Nest Hotel and the Chatswood Hotel if you want\n",
            "---------------\n",
            "The best fried chicken restaurant I would recommend is the [Cayswater Wharf](http://www.iscafesydney.com.au/). Great steaks and a nice atmosphere.\n",
            "\n",
            "Have fun!\n",
            "Hey /r/sydney, I've just got a new job in Sydney for the next two years and I'm starting to think I'd like the chance to meet some new people. I'd do interesting things, but I'm not sure if you could meet any friendly (maybe?) new people,\n",
            "---------------\n",
            "The best fried chicken restaurant I would recommend is the 'KFC' one down in the same alley.\n",
            "\n",
            "Food is alright but there's a place called **Jang Ta Bal** that's pretty good but it can get expensive. \n",
            "\n",
            "If you like Pappa Rich, [this place](http://www.pappa Rich.com/) has some fantastic Malaysian food there. \n",
            "\n",
            "Not sure about the cuisine. Try and get there early (late morning) and find some parking (there's always a line). \n",
            "---------------\n",
            "The best fried chicken restaurant I would recommend is the [Pork roll](http://www.pork rolls.com.au/) in Sussex St.  The place serves great food, and they also have a buffet where you can get a buffet buffet if you choose to sit and watch their movie.\n",
            "\n",
            "\n",
            "In terms of Japanese BBQ - there's [an amazing sushi train](http://www.google.com.au/search?q=aru%20buffet,+Haymarket,+Haymarket,+Haymarket,\n",
            "---------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python sample.py config/train_reddit_softmax1.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1nWJQCFLR7P",
        "outputId": "71109975-a953-4ac2-95db-18d764fee4fb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding config with config/train_reddit_softmax1.py:\n",
            "gradient_accumulation_steps = 1\n",
            "batch_size = 64\n",
            "block_size = 256 # context of up to 256 previous characters\n",
            "n_layer = 6\n",
            "n_head = 6\n",
            "n_embd = 768\n",
            "dropout = 0.2\n",
            "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\n",
            "max_iters = 100000\n",
            "lr_decay_iters = 100000\n",
            "min_lr = 1e-4 # learning_rate / 10 usually\n",
            "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\n",
            "warmup_iters = 100 # not super necessary potentially\n",
            "eval_interval = 1000\n",
            "eval_iters = 20\n",
            "log_interval = 10\n",
            "always_save_checkpoint = True\n",
            "dataset = 'reddit'\n",
            "\n",
            "out_dir = 'out-reddit-softmax-one'\n",
            "wandb_log = True\n",
            "wandb_project = 'nanoGPT_softmax1'\n",
            "wandb_run_name = 'reddit-mini-gpt-softmax-one'\n",
            "use_softmax1 = True\n",
            "softmax1_c = 1e-3\n",
            "detect_from_iter_num = -1\n",
            "\n",
            "start = \"The best fried chicken restaurant I would recommend is\"\n",
            "max_new_tokens = 100\n",
            "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
            "Used softmax1, c = 0.001\n",
            "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
            "Used softmax1, c = 0.001\n",
            "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
            "Used softmax1, c = 0.001\n",
            "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
            "Used softmax1, c = 0.001\n",
            "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
            "Used softmax1, c = 0.001\n",
            "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
            "Used softmax1, c = 0.001\n",
            "number of parameters: 81.11M\n",
            "No meta.pkl found, assuming GPT-2 encodings...\n",
            "The best fried chicken restaurant I would recommend is the Crystal Palace, Palace Verona in Paddington. \n",
            "\n",
            "If you are in the area, check out the [Chifley Square Food Hall](http://www.chifleyfoodhall.com.au/). Its next door to the Entertainment Centre, and is right by the station. Right by the light rail stops.\n",
            "\n",
            "[Here is Facebook page](https://www.facebook.com/CenturyNews/videos/139424763051373367\n",
            "---------------\n",
            "The best fried chicken restaurant I would recommend is in the CBD. \n",
            "\n",
            "The real issue is that although it's always more expensive, it's always better than eating at restaurants. \n",
            "\n",
            "Also, depending on how far you're willing to go - the food courts in Chinatown are better, but I'm not 100% on that. \n",
            "\n",
            "At $5 they also have a decent supply of frozen yogurt. \n",
            "i have a 1TB one, gotta get rid of it. haven't had a lot of time to buy\n",
            "---------------\n",
            "The best fried chicken restaurant I would recommend is La Disfida in Haberfield.\n",
            "I love it!\n",
            "Slept in for the first time last night, I feel better. Today is going to be one of those days where I don't go to work, and I'm kind of prepared for a 1 hour break from work.\n",
            "\n",
            "Also very nearly done with the thesis, but I have to go back to work :(\n",
            "Was that the pedestrian crossing though? The pedestrian crossing is still on a green light, and crossing\n",
            "---------------\n",
            "The best fried chicken restaurant I would recommend is the one on the corner of George and Liverpool Streets. It's always packed with other people and they normally clean out after the usual crowd.\n",
            "\n",
            "I've never had an issue with the marinated beef I'm friends with. \n",
            "\n",
            "My suggestion is to get the roast pork you want from a Korean butcher but that's what I've heard when I was a kid. \n",
            "&gt; In order to avoid being pushed to a seat, you must have to stand up.\n",
            "\n",
            "\n",
            "---------------\n",
            "The best fried chicken restaurant I would recommend is Pasteur in Burwood. \n",
            "\n",
            "The best is for you to try the Vietnamese place in Burwood, it's very close to the train station. \n",
            "\n",
            "I never really enjoyed Ashfield but that place is still a goer. \n",
            "There's a place that does it on the opposite corner of Park St and Liverpool St near the corner of Parramatta Rd. They do quite good spicy spicy chicken...\n",
            "\n",
            "http://www.urbanspoon.com/r/\n",
            "---------------\n",
            "The best fried chicken restaurant I would recommend is in the rocks just across the road from the pub.\n",
            "\n",
            "I can't remember the name of the place but its the same guys that does Gourmet Hot Wheels if you're into that sort of thing.\n",
            "\n",
            "Also the closest I can think of is at [The Dip](http://sydney.thedip.com/), Glebe.  They have a huge menu and the drinks are very cheap.\n",
            "\n",
            "But you can also get in and out of department stores a\n",
            "---------------\n",
            "The best fried chicken restaurant I would recommend is The Counter Burger in Newtown.\n",
            "\n",
            "One of the best Mexican restaurants in Sydney, hands down.\n",
            "\n",
            "It's across the road from Central Station.\n",
            "\n",
            "Also, if you want a great burger, go to a Snacks place in the city.\n",
            "\n",
            "Check out their Facebook page.\n",
            "\n",
            "There's also a [Facebook Page](http://www.facebook.com/snacks/) saying that Sydney is the one that has been suggested and we're getting there on our first visit\n",
            "---------------\n",
            "The best fried chicken restaurant I would recommend is the one in the cbd? it's overpriced for what it is, and if you don't mind it you definitely can't go wrong.\n",
            "\n",
            "edit: a word\n",
            "Can't tell if you're an asshole or a bogan.\n",
            "I didn't know you guys did that. It's well known that there are now four people on the same level. I'd quite like to have made the thread to point out that he's been downvoted so hard to the point of\n",
            "---------------\n",
            "The best fried chicken restaurant I would recommend is the one at the bottom of the building in the basement level of the Level 1 Market City.\n",
            "\n",
            "The Thai on the corner of Market City and Park, opposite the Hilton (Sydney Tower). They serve unlimited spicy curries (or hotdog, fried chicken) with a $79, sauna, rice and some veggies. It's a bit of a hike from the city.\n",
            "\n",
            "But the best thing to do is to find a parking spot that's within 5 mins walk of\n",
            "---------------\n",
            "The best fried chicken restaurant I would recommend is the one on the upper levels of the Dixon St Dixon House building.\n",
            "\n",
            "The fried chicken is pretty good too.\n",
            "I'm awake... and it's been a long day.\n",
            "\n",
            "I'm bored.\n",
            "\n",
            "Not looking forward to sleep, I'm watching some episodes of The Office and the rest of the week are gone.\n",
            "\n",
            "At least I get to spend the day in bed watching some anime.\n",
            "\n",
            "I just don't feel like this week will be over yet.\n",
            "\n",
            "---------------\n"
          ]
        }
      ]
    }
  ]
}